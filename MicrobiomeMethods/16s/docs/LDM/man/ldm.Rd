% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LDM_fun.R
\name{ldm}
\alias{ldm}
\title{Testing hypotheses using a linear decomposition model (LDM)}
\usage{
ldm(formula, data = .GlobalEnv, tree = NULL, dist.method = "bray",
  dist = NULL, cluster.id = NULL, strata = NULL, how = NULL,
  perm.within.type = "free", perm.between.type = "none",
  perm.within.ncol = 0, perm.within.nrow = 0, n.perm.max = NULL,
  n.rej.stop = 20, seed = NULL, test.global = TRUE,
  test.otu = TRUE, fdr.nominal = 0.1, square.dist = TRUE,
  center.dist = TRUE, scale.otu.table = TRUE,
  center.otu.table = TRUE, freq.scale.only = FALSE)
}
\arguments{
\item{formula}{a symbolic description of the 
model to be fitted. The details of model specification are given under 
"Details".}

\item{data}{an optional data frame, list or environment (or object coercible 
by as.data.frame to a data frame) containing the covariates of interest and 
confounding covariates. 
If not found in \code{data}, the covariates are taken from environment(formula), 
typically the environment from which \code{ldm} is called. The default is .GlobalEnv.}

\item{tree}{a phylogenetic tree. Only used for calculating a 
phylogenetic-tree-based distance matrix. Not needed if the calculation of 
the requested distance does not involve a phylogenetic tree, or if the 
distance matrix is directly imported through \code{dist}.}

\item{dist.method}{method for calculating the distance measure, partial
match to all methods supported by \code{vegdist} in the \code{vegan} package
 (i.e., "manhattan", "euclidean", "canberra", "bray", "kulczynski", "jaccard", 
 "gower", "altGower", "morisita", "horn", "mountford", "raup" , "binomial", 
 "chao", "cao", "mahalanobis") as well as "hellinger" and "wt-unifrac". 
 Note that the option \code{binary} is set to \code{FALSE} 
 (i.e., not allowing calculation of presence-absence distances) 
 when we internally call \code{vegdist} for its supported distances. 
 The Hellinger distance measure (\code{dist.method="hellinger"}) takes the form
 \code{0.5*E}, where E is the Euclidean distance between the square-root-transformed 
 frequency data. The weighted UniFrac distance (\code{dist.method="wt-unifrac"}) 
 is calculated by interally calling \code{GUniFrac} in the \code{GUniFrac} package.
  Not used when anything other than \code{dist=NULL} is specified for \code{dist}.
  The default is "bray".}

\item{dist}{a distance matrix. Can be an object of class either "dist" or "matrix".
The elements of the distance matrix will be squared and then the matrix will be centered if the default choices 
\code{square.dist=TRUE} and \code{center.dist=TRUE} are used. If \code{dist=NULL}, the distance matrix is 
calculated from the \code{otu.table}, using the values of \code{dist.method} (and \code{tree} if required). 
The default is NULL.}

\item{cluster.id}{character or factor variable that identifies clusters. The default value
cluster.id=NULL if the observations are not clustered (i.e., are independent).}

\item{strata}{a character or factor variable that defines strata (groups), within which to constrain permutations. 
The default is NULL.}

\item{how}{a permutation control list, for users who want to specify their own call to the \code{how} function from the \code{permute} package.
The default is NULL.}

\item{perm.within.type}{a character string that takes values "free", "none", "series", or "grid".
The default is "free" (for random permutations).}

\item{perm.between.type}{a character string that takes values "free", "none", or "series".
The default is "none".}

\item{perm.within.ncol}{a positive integer, only used if perm.within.type="grid". 
The default is 0.  See documentation for permute package for additional details}

\item{perm.within.nrow}{a positive integer, only used if perm.within.type="grid". 
The default is 0.  See documentation for permute package for additional details}

\item{n.perm.max}{the maximum number of permutations.  The default is NULL, in which case a maximum of
5000 permutations are used for the global test and a maximum of \code{n.otu} * \code{n.rej.stop} * (1/\code{fdr.nominal}) 
are used for the OTU test, where \code{n.otu} is the number of OTUs.  If a numeric value for \code{n.otu} is specified, 
this value is used for both global and OTU-level tests.}

\item{n.rej.stop}{the minimum number of rejections (i.e., the permutation 
statistic exceeds the observed statistic) to obtain before stopping. The 
default is 20.}

\item{seed}{an integer seed for the random number generator in the 
permutation procedure. The default is NULL; with the default value, an integer seed will be 
generated internally and randomly. In either case, the integer seed will be stored
in the output object in case 
the user wants to reproduce the permutations.}

\item{test.global}{a logical value indicating whether to perform the global 
test. The default is TRUE.}

\item{test.otu}{a logical value indicating whether to perform the 
OTU-specific tests. The default is TRUE.}

\item{fdr.nominal}{the nominal FDR value. The default is 0.1.}

\item{square.dist}{a logical variable indicating whether to square the 
distance matrix. The default is TRUE.}

\item{center.dist}{a logical variable indicating whether to center the 
distance matrix as described by Gower (1966). The default is TRUE.}

\item{scale.otu.table}{a logical variable indicating whether to scale the rows of the OTU table for the freq scale.  For count 
data, this corresponds to dividing by the library size to give relative frequencies.  Does not affect the tran scale.  
The default is TRUE.}

\item{center.otu.table}{a logical variable indicating whether to center the 
columns of the OTU table. The OTU table should be centered if the distance 
matrix has been centered. Applies to both the frequency and transformed scales.  The default is TRUE.}

\item{freq.scale.only}{a logical variable indicating whether to perform analysis of the frequency-scale data only (not the arcsin-root transformed frequency data and 
the omnibus test). The default is FALSE.}
}
\value{
a list consisting of 
  \item{b}{the matrix B as defined in Hu and Satten (2018)} 
  \item{dist}{the (squared/centered) distance matrix} 
  \item{x.freq}{the frequency-scale data matrix, scaled and centered if so specified} 
  \item{d.freq}{a vector of the nonnegative diagonal elements of \code{D} that satisfies
  \code{b^T x.freq = D v^T}}
  \item{v.freq}{the v matrix with unit columns that satisfies
  \code{b^T x.freq = D v^T}}
  \item{x.tran}{the (column-centered) arcsin-root-transformed 
  data matrix} 
  \item{d.tran}{a vector of the nonnegative diagonal elements of \code{D} that satisfies
  \code{b^T x.tran = D v^T}}
  \item{v.tran}{the v matrix with unit columns that satisfies
  \code{b^T x.tran = D v^T}}
  \item{low}{a vector of lower indices for confounders (if there is any) and submodels}
  \item{up}{a vector of upper indices for confounders (if there is any) and submodels}
  \item{VE.global.freq.confounders}{Variance explained (VE) by confounders, based on the frequency-scale data}
  \item{VE.global.freq.submodels}{VE by each submodel, based on the frequency-scale data}
  \item{VE.global.freq.residuals}{VE by each component in the residual distance, based on the frequency-scale data}
  \item{VE.otu.freq.confounders}{Contribution of each OTU to VE by confounders, based on the frequency-scale data}
  \item{VE.otu.freq.submodel}{Contribution of each OTU to VE by each submodel, based on the frequency-scale data}
  \item{VE.global.tran.confounders}{Variance explained (VE) by confounders, based on 
  the arcsin-root-transformed frequency data}
  \item{VE.global.tran.submodels}{VE by each submodel, based on 
  the arcsin-root-transformed frequency data}
  \item{VE.global.tran.residuals}{VE by each component in the residual distance, based on 
  the arcsin-root-transformed frequency data}
  \item{VE.otu.tran.confounders}{Contribution of each OTU to VE by confounders, based on 
  the arcsin-root-transformed frequency data}
  \item{VE.otu.tran.submodels}{Contribution of each OTU to VE by each submodel, based on 
  the arcsin-root-transformed frequency data}
  \item{VE.df.confounders}{Degree of freedom (i.e., number of components) associated with the VE for confounders}
  \item{VE.df.submodels}{Degree of freedom (i.e., number of components) associated with the VE for each submodel}
  \item{F.global.freq}{F statistics for testing each submodel, based on
  the frequency-scale data} 
  \item{F.global.tran}{F statistics for testing each submodel, based on 
  the arcsin-root-transformed frequency data} 
  \item{F.otu.freq}{F statistics for testing each OTU for each submodel, based on the frequency-scale data} 
  \item{F.otu.tran}{F statistics for testing each OTU for each submodel, based on the arcsin-root-transformed data} 
  \item{p.global.freq}{p-values for the global test of each set of covariates
  based on the frequency-scale data} 
  \item{p.global.tran}{p-values for the global test of each set of covariates
  based on the arcsin-root-transformed frequency data} 
  \item{p.global.omni}{p-values for the global test of each set of covariates 
  based on the omnibus statistics, which are the minima of the p-values obtained 
  from the frequency scale and the arcsin-root-transformed frequency data 
  as the final test statistics, and use the corresponding minima from the 
  permuted data to simulate the null distributions} 
  \item{p.otu.freq}{p-values for the OTU-specific tests based on the 
  frequency scale data} 
  \item{p.otu.tran}{p-values for the OTU-specific tests based on the 
  arcsin-root-transformed frequency data} 
  \item{p.otu.omni}{p-values for the OTU-specific tests based on the 
  omnibus statistics} 
  \item{q.otu.freq}{q-values (i.e., FDR-adjusted p-values) 
  for the OTU-specific tests based on the frequency scale data} 
  \item{q.otu.tran}{q-values for the OTU-specific tests based on 
  the arcsin-root-transformed frequency data} 
  \item{q.otu.omni}{q-values for the OTU-specific tests based on the 
  omnibus statistics} 
  \item{n.perm.completed}{number of permutations completed} 
  \item{global.tests.stopped}{a logical value indicating whether the 
  stopping criterion has been met by all global tests} 
  \item{otu.tests.stopped}{a logical value indicating whether the 
  stopping criterion has been met by all OTU-specific tests}
  \item{seed}{a single-value integer seed that is user supplied or internally generated}
}
\description{
This function allows you to simultaneously test the global association with the overall  
microbiome composition and individual OTU associations to give coherent 
results. It is capable of handling complex design features such as 
confounders, interactions, and clustered data.
}
\details{
The formula has the form

\code{otu.table ~ (first set of covariates) + (second set of covariates)
... + (last set of covariates)}

or

\code{otu.table | confounders ~ (first set of covariates) + (second set of covariates)
... + (last set of covariates)}

where \code{otu.table} is
the OTU table with rows for samples and columns for OTUs and each set of 
covariates are enclosed in parentheses. The covariates in each submodel (set of covariates) are tested jointly,
after projecting off terms in submodels that appear earlier in the model.

For example, given OTU table \code{y} and a data frame \code{metadata} that contains 4 covariates, 
\code{a}, \code{b}, \code{c} and \code{d},  
some valid formulas would be:

\code{y ~ a + b + c + d} ### no confounders, 4 submodels (i.e., sets of covariates)

\code{y ~ (a+b) + (c+d)} ### no confounders, 2 submodels each having 
2 covariates;

\code{y | b ~ (a+c) + d} ### \code{b} is a confounder, submodel 1 is 
\code{(a+c)}, and submodel 2 is \code{d}

\code{y | b+c ~ a*d}     ### there are 2 confounders \code{b} 
and \code{c}; there is 1 submodel consisting of the three terms \code{a}, \code{d}, and \code{a:d} (interaction). 
This example is equivalent to \code{y | b+c ~ (a+d+a:d)}.

\code{y | as.factor(b) ~ (a+d) + a:d}  ### now confounder 
\code{b} will be treated as a factor variable, submodel 1 will have the main 
effects \code{a} and \code{d}, and submodel 2 will have only the interaction 
between \code{a} and \code{d}

\code{y | as.factor(b) ~ (a) + (d) + (a:d)} ### there are 3 submodels \code{a}, \code{d}, and \code{a:d}.
Putting paratheses around a single variable is allowed but not necessary.

Submodels that combine character and numeric values are allowed; character-valued variables are coerced into factor 
variables.  Confounders are distinguished from other covariates as test statistics are not calculated for confounders
(which are included for scientific reasons, not by virtue of significance test results); 
consequently they also do not contribute to stopping criteria.  If tests of confounders are desired, confounders should
put on the right hand side of the formula as the first submodel.

LDM uses two sequential stopping criteria. For the global test, LDM uses the 
stopping rule of Besag and Clifford (1991), which stops permutation when a 
pre-specified minimum number (default=20) of rejections (i.e., the permutation 
statistic exceeded the observed test statistic) has been reached. For the 
OTU-specific tests, LDM uses the stopping rule of Sandve et al. (2011), 
which stops permutation when every OTU test has either reached the pre-specified 
number (default=20) of rejections or yielded a q-value that is below the 
nominal FDR level (default=0.1). As a convention, we call a test "stopped"
if the corresponding stopping criterion has been satisfied. Although all tests 
are always terminated if a pre-specified maximum number (see description of \code{n.perm.max} in Arguments list) of 
permutations have been generated, some tests may not have "stopped."  This typically occurs when
the relevant p-value is small or near the cutoff for inclusion in a list of significant findings; 
for global tests meeting the stopping criterion is not critical, but 
caution is advised when interpreting OTU-level tests that have not stopped as additional OTUs may be found 
with a larger number of permutations.
}
\examples{

#-----------------------------------------------
# fit only
#-----------------------------------------------
fit <- ldm(formula=throat.otu.tab | (Sex+AntibioticUse) ~ SmokingStatus+PackYears, 
          data=throat.meta, dist.method="bray", n.perm.max=0)

#-----------------------------------------------
# test the global hypothese only
#-----------------------------------------------
res1.ldm <- ldm(formula=throat.otu.tab | (Sex+AntibioticUse) ~ SmokingStatus+PackYears, 
               data=throat.meta, dist.method="bray", 
               test.global=TRUE, test.otu=FALSE, seed=123)
                    
#----------------------------------------------------
# test both the global hypothese and individual OTUs
#----------------------------------------------------
res2.ldm <- ldm(formula=throat.otu.tab | (Sex+AntibioticUse) ~ SmokingStatus+PackYears, 
               data=throat.meta, dist.method="bray", 
               test.global=TRUE, test.otu=TRUE, fdr.nominal=0.1, seed=123)

#----------------------------------------------------
# clustered data
#----------------------------------------------------
res4.ldm <- ldm(formula=sim.otu.tab | X ~ Y, data=sim.meta, dist.method="bray", 
               cluster.id=ID, perm.between.type="free", perm.within.type="none",
               test.global=TRUE, test.otu=TRUE, fdr.nominal=0.1, seed=123)
}
\references{
Hu YJ, Satten GA. (2019) Testing hypotheses about microbiome 
  using the linear decomposition model. 
  bioRXiv:doi.org/10.1101/229831.
}
\author{
Yi-Juan Hu <yijuan.hu@emory.edu>, Glen A. Satten <gas0@cdc.gov>
}
\keyword{microbiome}
